\chapter[Methodiken und Visualisierung]{Methodiken und Visualisierung für Continuous Integration und Feature Branches}
\label{ch:visu_meth}

Im vorangegangenen Kapitel wurde dargelegt, was Continuous-Integration und Feature-Branches sind und wie diese Techniken in der Softwareentwicklung angewendet werden. Zudem wird darauf eingegangen, welche Schwierigkeiten mit der Verwendung dieser Techniken einhergehen und dementsprechend eine Lösung erfordern. 
Die nachfolgenden Abschnitte sollen mögliche Methodiken und Visualisierungen beleuchten und dadurch Lösungsansätze anbieten. Es wird auf Schwierigkeiten von bekannten Techniken und Methodiken eingegangen und erläutert, wie häufige Fallstricke vermieden werden können.

\section{Continuous-Integration und Feature Branches}

Continuous-Integration und Feature-Branches sind beides Techniken, um die Kollaboration zwischen Entwicklern zu fördern. Continuous-Integration fordert die Integration in den existierenden Codestand für jede Änderung. Durch die Verwendung des Trunk-Based-Developments, ist das gesamte Team von dieser Integration direkt betroffen. Ist die Integration fehlerhaft, wird somit für die Dauer der Behebung, das gesamte Team angehalten, bei der Behebung zu helfen. Der Feature-Branch-Ansatz hingegen, lässt Änderungen ohne Integration parallel existieren. Folgt man der Gitflow-Verwendung von Feature-Branches aus Kapitel~\ref{subsec:gitflow}, wird auch hier eine Integration gefordert. Allerdings erst deutlich verzögert, etwa zu einem Release. Feature-Branches bieten somit einen Integrationsvorgang, ohne das Team zu blockieren. Allerdings wird der Zeitpunkt der Integration verzögert. In dieser Zeitspanne können weitere Änderungen zum Integrations-Branch hinzukommen. Jeder dieser Änderungen muss wiederum in den Feature-Branch integriert werden. Damit steigt der Aufwand sukzessive, über die Lebensdauer des Feature-Branches. Im ungünstigsten Fall eskaliert dieser Vorgang in einem ``big scary merge'' oder ``big bang merge'', wie in Kapitel~\ref{sec:feature-branches} beschrieben. Dieses Risiko sollte gemindert werden, durch eine regelmäßige und kontinuierliche Integration mit dem Integrations-Branch.\\

\blockquote {Continuously is more often than you think.}\footcite[vgl.][Kap. Continuous Integration]{humble2010}\\

Besonders aufwändige Arbeiten sollten stets in kleinere Arbeitspakete gegliedert werden. Dies ermöglicht teilweise eine fokussierte Abarbeitung und Parallelisierung der Arbeiten. Bestimmte Arbeitsschritte werden aufwändiger, umso länger sie nicht bearbeitet werden. Bei solchen Tätigkeiten ist eine zeitnahe Bearbeitung zu priorisieren.
Anwendet auf die Integration von Feature-Branches, sollten diese regelmäßig den Basis-Branch integrieren. Die erhöhte Frequenz vereinfacht die einzelnen Integrationsschritte.\\

\blockquote {When it is painful, the way to reduce the pain is to do it more frequently, not less}\footcite[vgl.][S.24]{humble2010}\\

Viele einzelne Integrationsschritte helfen die einzelnen Änderungen und ihre Motivation leichter zu erkennen. Dadurch sind komplizierte Merges leichter durchzuführen und es entstehen weniger Folgefehler.
 
Zielstellung der Vereinigung von Continuous-Integration und Feature-Branches ist folglich eine kontinuierliche Integration ohne Blockaden für andere Entwickler. Es muss definiert werden, wie Entwicklungssysteme und -werkzeuge ineinander greifen und es sollten Regeln und Strukturen definiert werden, um einen Ablauf mit nur wenig Reibungspunkten zu gewährleisten.

\subsection{Automatisierter Test von Feature-Branches}

Als erste Schritt zur Verschmelzung von Continuous-Integration und Feature-Branches ist es notwendig, jede Änderung automatisch zu testen. Dazu muss jede Änderung auf einem Feature-Branch in einem zentralen Repository bereitgestellt werden. Der Stand des Feature-Branches muss dann wie in Kapitel~\ref{sec:automation-software} \nameref{sec:automation-software} beschrieben, erstellt und getestet werden.

Prinzipiell besteht die Möglichkeit, einen Test der Änderungen manuell auf dem Entwicklersystem auszuführen. Dieses Vorgehen erfordert allerdings eine hohe Anzahl an Werkzeugen und blockiert den Entwickler für diesen Zeitraum.

Die Bereitstellung in einem zentralen Repository ermöglicht es, statische und syntaktische Analysen zu erstellen. Die Ausführung der vollständigen Test-Suite erlaubt semantische Analysen. Die zentrale Aufbereitung der Ergebnisse der Analysen ermöglicht es allen Projektteilnehmern, eine Einschätzung des Feature-Branches vorzunehmen.

\subsection{Bewertung von Änderungen - Software-Metriken}
\label{subsec:main-metrics}

Tom DeMarco schrieb über Software-Metriken:

\blockquote{You can’t manage what you can’t control, and you can’t control what you
don’t measure. To be effective software engineers or software managers, we
must be able to control software development practice. If we don’t measure
it, however, we will never have that control.}\footcite{demarco1986}
\\

Um Änderungen an einer Software-Anwendung zu bewerten und automatisiert Entscheidungen zu treffen, müssen die Änderungen quantifiziert und mit Vergleichswerten in Beziehung gesetzt werden. Für die Quantifizierung können Software-Metriken aus  Kapitel~\ref{subsubsec:base-metrics} verwendet werden. Da Aussagen über Programmkomplexität und Umfang kein hinreichende Bewertung ermöglichen, müssen zudem Verfahren zur Verifikation herangezogen werden. Die übliche Variante hierfür, ist eine umfangreiche Test-Suite und je nach Anwendung auch Verfahren, wie die in Kapitel~\ref{subsubsec:base-verification} beschriebene Modellprüfung und die abstrakte Interpretation.

In der Praxis werden automatisiert oft nur Tests verwendet. Der geringer Aufwand für ihre Erstellung und eine gute Skalierbarkeit sorgen für einen flexiblen Einsatz. 

Einzelne Ergebnisse durch Metriken können nicht für die Bewertung eines automatischen Software-Builds verwendet werden. Die Abbildung auf eine einheitliche Skala oder der Vergleich mit Fixpunkten erlaubt eine Bewertung der Ergebnisse. Die Auswahl der Fixpunkte ist stark abhängig von der verwendeten Metrik. Komplexitäts-, Umfangs- und Strukturmetriken liefern Werte, die nur schwer automatisiert zu bewerten sind. Hier bietet sich die Betrachtung der kurz- und langfristigen Änderung an. Sprunghafte Änderungen sollten dabei von besonderer Signifikanz sein. Prüfungen auf den Grad der Erfüllung eines Aspektes sind gut zu automatisieren. Die Testabdeckung einer Softwareanwendung kann auf 80\% festgelegt werden und darf an keiner Stelle unterschritten werden. Eine solche Prüfung sollte einen direkten Einfluss, auf das Ergebnis des automatisierten Software-Builds, ausüben. Der Grad der Erfüllung eines Aspekts kann auch genutzt werden um einen Prozess zu unterstützen. Soll die Testabdeckung in einem Softwareprojekt stetig erhöht werden, kann der Prozentsatz automatisch angepasst werden. Als Start würde der aktuelle Grad der Erfüllung verwendet werden. Bei jeder Überschreitung des Wertes, wird dieser auf den aktuellen Wert angepasst. Auf diese Weise wird eine Verringerung  der Testabdeckung verhindert und die Erstellung von Testfällen für neuen Code gefordert. Ob der Schwellwert zusätzlich in Intervallen erhöht wird, hängt stark vom Entwicklungsteam ab. Stagniert die Testabdeckung über einen längeren Zeitraum sind externe Erhöhungen sinnvoll.

Die Verwendung von Metriken und Testfällen erlauben keine grundsätzliche Aussage über die Qualität der Software. Richtig angewendet und gewartet, erlauben sie allerdings eine zuverlässige Absicherung des automatischen Software-Builds.

\subsection{Automatisches Zusammenführen}

Das Zusammenführen von Änderungen ist ein schwieriges Unterfangen. Während der Merge von Codeständen häufig automatisch möglich ist, kann keine semantische Validierung während des Merges vorgenommen werden. Die Validierung kann durch die Ausführung einer Test-Suite erfolgen. Zusätzliche Informationen können durch die Ausführung von Metriken gewonnen werden.

\subsubsection{Fastforward-Merges}

Fastforward-Merge ist ein Term für die Versionsverwaltung mit Git. Es bezieht sich auf das Verschieben eines Branch-Zeigers zu einem anderen Branch-Zeiger ohne die Zusammenführung von Änderung. Es werden lediglich bestehende Änderung des Ziel-Branches auf den Basis-Branch übertragen.
Fastforward-Merges sind gut zu automatisieren, da sie komplett von Git durchgeführt werden können. Dadurch können verschiedene automatisierte Verfahren auf Basis eines Fastforward-Merges aufgebaut werden.

\subsubsection{Flüchtige Release-Branches}

Release-Branches sind Branches mit der Funktion alle Änderungen für eine Veröffentlichung zu einem fixen Zeitpunkt zu sammeln. Dazu werden iterativ alle Feature-Branches auf dem Release-Branch zusammen geführt. Üblicherweise wird der Feature-Branch gelöscht, nach der Zusammenführung in den Release-Branch. Der Release-Branch wird somit iterativ aufgebaut und getestet. Abschließend werden die Änderungen auf den Master-Branch überführt und mit einem Tag markiert.

Dieses Vorgehen kann zu Problemen führen, wenn Änderungen eines Feature-Branches wieder aus dem Release-Branch entfernt werden müssen. Zudem treten mögliche Merge-Fehler und -Problem erst beim Zusammenführen mit dem Release-Branch auf.

Abhilfe könnte ein ``flüchtiger''-Release-Branch schaffen. Dazu müssten alle Feature-Branches markiert werden, die einen gemeinsamen Release-Branch bilden sollen. Die Feature-Branches können automatisch zusammengeführt geführt werden. Im Gegensatz zu einem regulären Release-Branch wird zusammengeführte Branch nicht veröffentlicht. Der flüchtige Release-Branch wird für die Ausführung von Tests und die Sammlung von Metriken verwendet. Mit einer guten Test-Suite und Metriken geben diese Daten eine Aussage über den Fortschritt des Releases. Die Anzahl von Änderungen und welche Änderungen einen Konflikt verursachen, können ermittelt werden. Die erkannten Konflikten können nun frühzeitig behoben werden. Dadurch können Branches auch in Kombination beurteilt werden. Im Gegensatz zu einem öffentlichen Release-Branch können die Änderungen weiter bearbeitet werden, ohne sich Gegenseitig zu blockieren. Zudem können einzelne Features mit wenig Aufwand aus dem Release entfernt werden. Diese Option wird geschwächt durch viele kombinierende Merges um Konflikte für den Release zu entfernen.

Wie effektiv diese Technik angewendet werden kann, hängt stark vom Grad der Kopplung der Software ab. Bei einem hohen Kopplungsgrad können Releases nur schwer getrennt werden. In jedem Fall gleicht diese Technik Schwächen von Feature-Branches aus. Branches werden häufig beurteilt und Probleme werden frühzeitig kommuniziert. Abhängig von der Form der Kommunikation der Daten, kann auf diese Weise ein guter Release-Fortschritt über alle Branches ermittelt werden. 

\section{Automatisierte Erstellung von graphischen Übersichten}

Angesichts der Komplexität mit der Entwickler häufig konfrontiert sind, ist es essentiell die richtigen Informationen zusammenzutragen. Je nach Situation können dabei andere Ansichten und Übersichten wichtig sein. In stark gewachsenen Softwareprojekten können mit den richtigen Visualisierungen Engpässe und interne Abgrenzungen gefunden werden. Es können Wachstum und Fortschritt eines Projektes visualisiert werden. Viele Ansichten sind zudem hilfreich um Informationen zwischen technisch versierten Parteien und technisch weniger versierten Parteien zu transportieren.

Wesentlich bei diesen Ansichten ist der Aufwand für ihre Erstellung. Ansichten die einen hohen manuellen Aufwand erfordern, veralten schnell und werden nicht mehr genutzt. Im schlimmsten Fall liefern veraltet Ansichten falsche Informationen. Somit ist es entscheidend diese Ansichten und Übersichten automatisch zu erstellen. Über Metriken aus dem automatisierten Softwareerstellungsprozess, können die notwendigen Messwerte ermittelt werden. 

Da in graphische Übersichten Trends und Schwerpunkte erkannt werden sollen, bieten graphische Übersichten einen Vorteil gegenüber rein textbasierten Darstellungen. Ein einfacher und schneller Eindruck vom Projektfortschritt und der -Qualität kann damit erlangt werden.

Bewertungen von Feature-Branches und Releases können damit unterstützt werden.

\subsection{Übersicht zu Branches}

Szenarien in denen viele Branches zum Einsatz kommen, müssen den dadurch entstehenden zusätzlichen Aufwand berücksichtigen. Werden die zahlreichen Zustände des Software-Codes nicht entsprechend behandelt, kann ein erhebliche Mehraufwand durch Aktualisierung und Merging der Branches entstehen. Somit ist es notwendig Branches schnell zu beurteilen und einsortieren zu können.

Eine solche Übersicht müsste wichtigen Kriterien eines Branches gesammelt und übersichtlich bereit stellen. Solche Kriterien sind unter anderem:
\begin{itemize}
\item Alter des Branches
\item beteiligte Autoren
\item wie häufig in vergangener Zeit neue Änderungen auf den Branch eingebracht wurden (Puls)
\item Kennzahlen des Branches zu Qualität und Fortschritt
\end{itemize}

Durch diese Übersicht können schnell Entscheidungen getroffen werden, welche Branches in den Fokus gerückt werden müssen. Alte oder bereits in den Codestand überführte Branches können gelöscht werden. Branches mit schlechten Kennzahlen können zu einem Refactoring eingeplant werden. Branches mit vielen Änderungen geben Rückschluss auf den aktuellen Fokus der Entwickler. 

\subsection{Übersicht zu Releases}

\begin{figure}[htbp]
  \includegraphics[
    width=\textwidth,
    height=\textheight,
    keepaspectratio
  ]{resources/release-branch_overview.pdf}
  \caption{Prototyp - Releaseübersicht}
  \label{prototype-release-overview}
\end{figure}

Angelehnt an die Branch-Übersicht und die angesprochenen ``flüchtigen'' Release-Branches, können auch Release-Ansichten bereit gestellt werden. Neben den bereits in der Branch-Übersicht erwähnten Kriterien, können weitere Kriterien visualisiert werden. Kriterien für das Zusammenspiel der für das Release geplanten Branches wären zum Beispiel:
\begin{itemize}
\item Konflikte zwischen Branches
\item Abschätzung zum Fortschritt des Releases
\item Branches mit geringem Fortschritt
\item Blockierende Branches
\end{itemize}

Die Visualisierung von Konflikten und Blockaden kann die Beurteilung eines Release deutlich erleichtern. Die erleichterte Kommunikation von Konflikten hilft bei deren Fokussierung innerhalb eines Releases. Eine konkrete Aussage über den Fortschritt eines Releases ist nicht ohne Weiteres möglich. Es können allerdings Abschätzungen auf Basis des geschätzten Umfangs von Features vorgenommen werden. Zusammen mit Daten zu verbrauchter Arbeitszeit, getätigten Commits, Teststand und -abdeckung kann dieses Bild verbessert werden.

In Projekten verwendete Ticketverwaltungssysteme können eine ähnliche Ansicht bereit stellen. Diese beurteilen ebenfalls anhand von geplantem und gebuchtem Aufwand den Stand eines Releases.

Die zusätzlichen Informationen, aus dem Versionsverwaltungssystem, Tests und Metriken erweitern diese Ansicht. Ob diese Informationen einen Mehrwert darstellen, muss allerdings empirisch bewiesen werden.
Eine hohe Testdichte und Testqualität sollte die erhaltenen Informationen verbessern. Die Release-Übersicht profitiert somit besonders von Verfahren wie Test-Driven-Development (TDD). Über TDD wird in Kapitel~\ref{test-driven-development} näher eingegangen.

\subsection{Konfigurations- und Systemübersicht}
\label{subsubsec:configuration-system-overview}

Das Konfigurationsmanagement aus der automatisierten Softwareerstellung kann auch für eine System- und Konfigurationsübersicht verwendet werden. Zusammen mit Daten aus einer Systemüberwachung oder Virtualisierungs-Verwaltung lassen sich umfangreiche Rückschlüsse ziehen. 

Eine automatisierte Übersicht hat sowohl für vollautomatische Virtualisierungen Vorteile, als auch für teil-automatisierte oder manuell geführte Systemlandschaften.

In einer vollautomatisierten Virtualisierung werden Systeme automatisch bereitgestellt, verwaltet und wieder entfernt. Eine aussagekräftige Übersicht erleichtert sowohl die Fehlersuche, als auch das Erstellen von Auswertungen zu den Systemen. Viele Virtualisierungs-Verwaltungen sollten bereits zahlreiche Auswertungsmöglichkeiten bereitstellen. Aufgrund der allgemeingültigen Natur der Verwaltungen, werden diese aber nur bedingt auf spezifische Merkmale der Anwendungen eingehen können. Die semantischen Zusatzinformationen aus der Konfigurationsverwaltung gleichen diesen Nachteil aus.

Auch im Fall einer manuellen oder teil-automatisierten Virtualisierung oder Systemverwaltung bringt eine Systemübersicht Vorteile. Während in der vollautomatisierten Variante eine Systemübersicht meist automatisch mit erstellt wird, müssen im manuellen Fall die Übersichten extra erstellt werden. Wechselnde Belegungen der einzelnen Systeme sind häufig gegeben. Wird eine Umgebung benötigt für ein Testszenario, ist es häufig schwer festzustellen, welche Systeme verfügbar sind. In Kombination mit der Konfigurationsverwaltung können Systeme nicht nur anhand ihrer Verfügbarkeit beurteilt werden, sondern auch bezüglich ihrer Systemkompatibilität. Somit kann die Systemübersicht als Grundlage zur Verwaltung des Systempools verwendet werden.

Unabhängig von der verwendeten Systemverwaltung kann die Systemübersicht auch als Dashboard verwendet werden. Wird die Systemübersicht um Absprünge zum Build-Server und zur Systemverwaltung ergänzt, erreicht man einen übersichtlichen und zentralen Einstiegspunkt in den Systemlandschaft.

Eine Konfigurations- und Systemübersicht ist somit eine hilfreiche, kombinierte Ansicht. Zahlreiche Anwendungen sind denkbar, hängen allerdings stark von den verfügbaren Schnittstellen ab. Im Rahmen eines automatisierten Softwareerstellungsprozesses können bereits viele notwendige Informationen gesammelt werden. Daher sollte es immer möglich sein eine aussagekräftige Übersicht zu generieren.

\subsection{Übersichten für die Konfigurations- und Abhängigkeitsverwaltung}

Eine Abhängigkeitsverwaltung für die verwendeten Software-Bibliotheken beschreibt eindeutig, welche Komponenten und Versionen verwendet werden. Die Abhängigkeitsverwaltung löst dabei alle Anforderungen zu einem eindeutigen, möglichst aktuellen Set an Komponenten auf. 

Die Komposition der Abhängigkeiten ist ein komplizierter und komplexer Vorgang. Jede Abhängigkeit bringt neue Abhängigkeiten in die Verarbeitung ein. Viele der Abhängigkeitsverwaltungen nutzen reguläre Ausdrücke, um die benötigten Versionen der Abhängigkeiten zu beschreiben.

Das entstehende Abhängigkeitsgeflecht möglichst simpel zu halten, ist offensichtlich aus Gründen der Wartbarkeit sinnvoll. Muss eine Abhängigkeit aktualisiert werden, sollte schnell deutlich werden, welche anderen Abhängigkeiten betroffen sind.
Aber auch aus Gründen der Robustheit sind transparente Abhängigkeiten wichtig. Wenn Abhängigkeiten weitere Abhängigkeiten in das System einbringen, entstehen schnell größere Kaskaden. Zentrale, stark gekoppelte Komponenten in Abhängigkeitskaskaden sind problematisch. In schwierigen Fällen, müssen alle Abhängigkeiten der Komponente ebenfalls aktualisiert werden.

Um diesen Szenarien vorzubeugen und sie abzuschwächen, ist eine automatisierte Aufarbeitung der Abhängigkeiten sinnvoll. Übersichten die Knotenpunkte und Cluster schnell aufzeigen, sowie Metriken Abhängigkeiten formal erfassen.

Übersichten sind eine sinnvolle Ergänzung in einer Projekt- und Systemübersicht. In der automatisierten Softwareerstellung liegt der Fokus allerdings in der automatischen Bewertung der Software und ihrer Komponenten. Wird wie in Kapitel~\ref{subsec:dependency-management}~\nameref{subsec:dependency-management} eine Abhängigkeitsverwaltung verwendet, können weitere Maßnahmen zur Qualitätskontrolle ergriffen werden. Es sollte zudem zwischen internen und externen Abhängigkeiten unterschieden werden, da für die unterschiedlichen Typen, unterschiedliche Maßnahmen ergriffen werden können. Das Kapitel~\ref{par:structure-metrics}~\nameref{par:structure-metrics} beschreibt die Basis für diese Metriken. Zusätzlich sollten Abhängigkeiten auch nach ihrem Alter und ihrer abgeschätzten Qualität beurteilt werden.

Summiert und über einen längeren Zeitraum betrachtet bieten diese Informationen die Möglichkeit die Entwicklung der Anwendung besser zu beurteilen. Es können Strategien zur schrittweisen Verbesserung (refactoring) der Software ermittelt werden. Weiter können neue Änderungen beurteilt werden. Der Grad ihrer Vernetzung, der Aktualität der verwendeten Abhängigkeiten und wie gut sie sich in das Gesamtbild der Anwendung integrieren.

\subsubsection{Interne Abhängigkeiten}

Interne Abhängigkeiten sind meist das Resultat aus einer Modularisierung der Anwendung. Abgrenzungskriterien können hierfür logische, strukturelle oder ästhetische Gründe sein. Logische Gründe basieren auf dem Domainmodell der Anwendung und beschreiben unterschiedliche Ausprägungen und Ebenen der Anwendung. Strukturelle Gründe können Umfang eines Moduls, Wiederverwendbarkeit eines Moduls zwischen Modulen und Anwendungen oder eine klare Trennung der Verwendung von Bestandteilen des Moduls sein. Ästhetische Gründe begründen sich auf vereinbarten Coding-Guidelines, populären Softwareentwicklungsstrategien oder schlicht dem subjektiven Entwicklerempfinden. Interne Abhängigkeiten tendieren oft dazu weniger lose gekoppelt zu sein und implizite, nicht definierte Abhängigkeiten aufzuweisen.

Vorteilhaft an internen Abhängigkeiten ist der hohe Einfluss, der auf sie genommen werden kann. Gut verfügbare Quellen und Zugriff die zugehörige Infrastruktur, sollten gegeben sein. Dadurch können interne Anwendung isoliert getestet und mit Metriken geprüft werden. Dadurch können Kopplungsgrad und Abhängigkeiten gut inspiziert und optimiert werden. Weiter ergibt sich durch den direkten Zugriff auf die Quellen, auch die Möglichkeit eigenständig Regeln für die Erstellung von Versionen der Abhängigkeiten festzulegen. Komponenten die häufig zusammen verwendet werden, sollten im Falle einer Major-Version diesen Sprung der Version gemeinsam vollziehen. Häufig ist diese Strategie auch noch für Minor-Versionen sinnvoll. Dadurch lässt sich bereit anhand der Komponentendarstellung ein gemeinsames Bild zeichnen. Stark veraltet Versionen sind bei internen Abhängigkeiten nur bedingt ein Problem, da kritische Versionen oder Fehler in der Regel gut kommuniziert werden.

\subsubsection{Externe Abhängigkeiten}

Externe Abhängigkeiten sind häufig standardisierte Bibliotheken für Zugriffe, Verfahrensweisen oder komplette Frameworks. Externe Abhängigkeiten sind in der Regel lose gekoppelt und durch ihre breite Verwendung gut getestet und dokumentiert. Dabei sind indirekte Test durch die Verwendung der Bibliothek und Dokumentation durch Diskussion in Foren, Blogs und Frage-Portalen als Teil dessen zu sehen. 

Externe Abhängigkeiten bergen immer auch ein Risiko. Dieses Risiko ergibt sich zum Teil durch die schwer einschätzende Qualität. Robustheit und Fehleranfälligkeit sind bedingt definierbar. Ebenso sind sicherheitskritische Problem und Leistungsschwächen nur bedingt abschätzbar. Ein anderer Teil des Risikos ist die Öffnung der eigenen Software für potentiell gefährliche Softwarebestandteile. Häufig sind Abhängigkeiten zu komplex um sie vollständig zu untersuchen oder die Abhängigkeiten liegen nur in gepackter, nicht lesbarer Form vor. Die Abwehr solcher Softwarebestandteile ist nur bedingt möglich. Der wirksamste Schutz gegen dieses Risiko ist die Verwendung von quelloffener Software mit einer aktiven Entwickler-Community. Aber auch in diesem Szenario ist Schadsoftware möglich.

Die Aktualisierung von externen Abhängigkeiten sollte im Allgemeinen nur in kontrolliertem Maße erfolgen. Sicherheitskritische Updates sollten steht priorisiert werden. Aktualisierungen anderer Art sind allerdings kritisch zu sehen, da sie häufig mit Anpassung in den internen Strukturen zur Folge haben. Es muss somit abgewogen werden ob die notwendigen Anpassungen durch entsprechende Vorteile der Aktualisierung gedeckt werden.

Unabhängig des Abhängigkeitstyps sollte immer verhindert werden, dass die Abhängigkeiten unkontrolliert aktualisiert werden. Insbesondere wenn Major-Updates von Abhängigkeiten ohne Prüfung und Test genutzt werden, können leicht Schnittstellen brechen oder unerwartete Verhaltensmuster in der Anwendung auftreten.

\subsubsection{Darstellung der Abhängigkeiten}
\label{subsubsec:illustrate-dependencies}

In einer stark modularisierten Softwareanwendung existieren in der Regel sehr viele Abhängigkeiten. Starke Wiederverwendung von Modulen erhöht die Anzahl von Querreferenzen. Viele Module verwenden daher oft gleiche Module und Bilden daher zahlreiche Verbindungen. Eine einfache Darstellung dieser Verbindungen ist kaum möglich. 

Für die nachfolgenden Vergleiche werden zwei PHP-Projekte verwendet. In beiden Projekten wird als Paketverwaltung Composer\footcite{composer-web} genutzt. Composer beschreibt Abhängikeiten mittels einer eigenen DSL\footcite{composer-json}, welche auf Yaml\footcite{yaml-homepage} basierenden . Das erste Projekt ist eine Open-Source-Wiki-Anwendung ``Wikia''\footcite{wikia-github}. Sie zählt zu den größten Open-Source-PHP-Projekten\footcite{largest-php-apps-2018}. Das zweite Projekt ist eine mittel große Individualsoftware für ein Content-Management-System. 

Beide Projekte haben eine ähnliche Fülle an Abhängigkeiten und werden in einem ähnlichen Fachgebiet genutzt. Die unterschiedliche Entwicklungskultur, kann aber unter Umständen Einfluss auf das Softwareergebnis haben.

\paragraph{Gerichteter Graph}

\begin{figure}[htbp]
  \includegraphics[
    width=\textwidth,
    height=\textheight,
    keepaspectratio
  ]{resources/dependency-graph.pdf}
  \caption{Gerichteter Graph für Abhängigkeiten}
  \label{dependency-graph}
\end{figure}

In Abbildung~\ref{dependency-graph} wurden die Abhängigkeiten der beiden Projekte in gerichtet Graphen transformiert. Dafür wurde eine PHP-Bibliothek ``clue/graph-composer'' verwendet. 

Auffällig bei beiden Projekten sind zentrale Knoten, also Abhängigkeiten die von vielen anderen Abhängigkeiten genutzt werden oder diese nutzen. Des weiteren könnten Gruppen von Abhängigkeiten ausgemacht werden. Solche Gruppen können ein eigenes, größtenteils abgrenzbares Abhängigkeitsnetz spannen. Damit dies möglich ist, müssten die Abhängigkeiten entsprechend gewichtet angeordnet sein. Im Falle des Graph-Composer-Werkzeuges erscheint dies nur mangelhaft zu gelingen. 

Abschließend sind in der Individualsoftware noch eine Reihe an unerwarteten Blattknoten erkennbar. Diese deuten auf schlecht gepflegte Abhängigkeiten hin. Unzureichende gepflegte Abhängigkeiten entstehen in der Regel, wenn die betroffenen Module nur im Gesamtkontext geprüft werden. Dadurch sind für diese Module, implizit Abhängigkeiten verfügbar, die sonst nicht nicht bereitgestellt werden könnten.

\paragraph{Kreisdiagramm}

\begin{figure}[htbp]
  \includegraphics[
    width=\textwidth,
    height=\textheight,
    keepaspectratio
  ]{resources/circle-plot-dependencies.pdf}
  \caption{Kreisdiagramme für Abhängigkeiten}
  \label{dependency-circle-plot}
\end{figure}

In Abbildung~\ref{dependency-circle-plot} werden zwei Kreisdiagramme verwendet um die Abhängigkeitszu- und abflüsse zu verdeutlichen. Das linke Diagramm stellt die Abhängigkeiten einer mittel großen Individualsoftware für ein Content-Management-System dar. Das rechte Diagramm visualisiert die Abhängigkeiten der . Die Wahl des Kreisdiagramms ergibt sich durch seine Eignung gruppierte Ab- und Zuströme zu visualisieren\footcite{visualizing-graph-data}. 

Als Basis für die beiden Diagramme wurden die im Versionsverwaltungssystem gesichert Dateien der Packetverwaltung verwendet. Das beschreibende Format ist eine DSL von Composer\footcite{composer-json} und wird primär für PHP-Projekte verwendet. Die Ansicht wurde mit Hilfe eines JavaScript-Werkzeuges ``Dependency Wheel''\footcite{composer-dependency-wheel} erstellt.

Die grauen Abhängigkeitsteile stellen direkte Abhängigkeiten des Projektes dar, während die farbigen Stränge die Verbindungen der Abhängigkeiten visualisieren.

In der Darstellung der Individualsoftware, sind die roten Stränge interne Abhängigkeiten. Für Wikia sind Abhängigkeiten der eigenen Entwicklung Lila.

Beide Diagramme vermitteln einen guten Eindruck zur Fülle der Abhängigkeiten und eine Überblick darüber, wie viele Fremdabhängigkeiten im Projekt verwendet werden. Darüber hinaus sind allerdings nur schwer Informationen aus den sichtbaren Daten zu gewinnen. Zentrale Abhängigkeiten und Knoten lassen sich kaum ausmachen.

\subsection{Übersichten für Software-Metriken}

Metriken liefern diskrete Werte. Diese eigenen sich besonders für die maschinelle und automatisierte Verarbeitung. Sollen Entwickler anhand von Werten aus Metriken Entscheidungen treffen, stoßen diese schnell an kapazitive Grenzen. Visuelle Aufbereitungen dieser Werte helfen bei der Einordnung der Zahlen. Vergleiche zwischen Kenngrößen, Trends über Zeiträume und Gruppen von Werten lassen sich besser erfassen. Übersichtliche und gut aufbereitete Darstellungen helfen bei der Priorisierung und Bewertungen verschiedene Konstellationen. Abstrakte Sachverhalten wie Komplexität und Wartbarkeit können so erfasst werden.

\begin{figure}[htbp]
  \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]
    {resources/900x300.pdf}
  \caption{TODO Graphik zu Liniendiagrammen (verbundene Punkte vs Trend zwischen Punkten}
  \label{line-chart}
\end{figure}
\paragraph{Liniendiagramme} eignen sich besonders, um Trends und zeitliche Verläufe darzustellen. Zentrale und wichtige Größen, wie Testabdeckung, Komplexität, Kopplungsgrad können dadurch zeitlich betrachtet werden. 

Liniendiagramme eignen sich daher eher für langfristige Betrachtungen. Risikoabschätzung, Qualitätsentwicklung und Planung von Refactoring sind denkbare Einsatzgebiete.

\begin{figure}[htbp]
  \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]
    {resources/900x300.pdf}
  \caption{TODO Graphik zu Balkendiagrammen, horizontal, vertikal}
  \label{bar-chart}
\end{figure}
\paragraph{Balkendiagramme} eignen sich für vergleichende Ansichten. Kenngrößen die ohne Vergleich schwer zu bewerten sind, können so in Kontext gesetzt werden. Werden die Balken sortiert, können zudem Wertgruppen eingeteilt werden. Durch die Drehung des Balkendiagramms um 90 Grad, wird zudem der Fokus stärker auf die Sortierung gelenkt.

Balkendiagramme bilden Werte in einer gut vergleichbaren Form an. Dadurch eigenen sie sich besonders für Priorisierung und Gruppierung von Merkmalen.
Die Identifizierung der Gruppe der komplexesten Klassen. Oder die Gruppe der Klassen mit den meisten Abhängigkeiten können so schnell festgestellt werden. Mit Hilfslinien, parallel zu den Achsen, lassen sich gut Grenz- und Schwellwerte darstellen.

\begin{figure}[htbp]
  \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]
    {resources/900x300.pdf}
  \caption{TODO Graphik zu Kreisdiagrammen, Ringdiagramme}
  \label{circle-chart}
\end{figure}
\paragraph{Kreis- und Ringdiagramme} eignen sich gut um Zusammensetzungen darzustellen. Werden mehrere Zusammensetzungen als Ringdiagramme verschachtelt, lassen diese sich in Grenzen auch vergleichen. Kreisdiagrammen können verhältnismäßig schlecht kleinere Anteile darstellen. Unter anderem Beschriftungen können bei kleinen Teilen nur schwer dargestellt werden.

Besonders Verhältnisse zwischen Größen können mit Kreisdiagrammen gut dargestellt werden. Ähnlich zum Balkendiagramm, können sie sortiert und gruppiert Mehrheitsverhältnisse darstellen. Insbesondere Verhältnisse, die die Vertikale oder Horizontale Linie überschreiten, können gut argumentiert werden. So ist zum Beispiel die 50\% Marke in einem Kreisdiagramm eine gute Orientierungshilfe. Im Vergleich zum Balkendiagramm lassen sich diskrete Werte schwerer visualisieren.

\begin{figure}[htbp]
  \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]
    {resources/bubble-complexity-chart.pdf}
  \caption{Blasendiagramm für Cyclomatische-Komplexität}
  \label{bubble-complexity}
\end{figure}
\paragraph{Blasendiagramme} eigenen sich besonders für die relative Darstellung von Werten. Oftmals werden die Blasen zusätzlich an den Achsen eines Graphen dargestellt. Im dargestellten Beispiel wurden die Blasen sortiert aufgereiht. Jede Blase steht im Beispiel für eine Klasse und die Größe der Blase für den Wert ihrer Cyclomatischen-Komplexität. Die Farbe der Klasse stellt einen Index für ihre Wartbarkeit zusammen. Die Darstellung ist eine Zusammenfassung der PHPMetrics-Bibliothek. 
Die Darstellung vermittelt relativ einfach die Menge und Stärke von Komplexität und potentiellen Wartungsschwierigkeiten.


\section{Automatisierte Systembereitstellung}

Um Feature-Branches technisch zu unterstützen, müssen Tests und Metriken für jeden Feature-Branch ausgeführt werden. Damit dies automatisiert möglich ist, müssen die zugehörigen Testsysteme automatisch zur Verfügung gestellt werden. Somit ist eine automatisierte Systembereitstellung notwendig.

Die automatische Bereitstellung ist prinzipiell, sowohl mit Virtualisierung, als auch mit einem Containersystem möglich. Auch eine entsprechende verwaltet Gruppe an Hardwaresystemen ist möglich, sollte allerdings in den meisten Situation deutlich unwirtschaftlicher sein, als die virtuellen Lösungen.

Die Entscheidung für eine Virtualisierungs- oder Containerlösung sollte von Fall zu Fall entscheiden werden. Die schlankere und damit Resourcen schonendere Lösung, ist die Verwendung von Containern. Mit ihnen können problemlos einzelne Testsysteme oder komplexere Service und Systemverbände erstellt und verwaltet werden. Die Verwendung eines einzelnen Container-Systems ist nicht mehr möglich, wenn unterschiedliche Betriebs- oder Hardwaresysteme benötigt werden. In diesem Fall müssen mehrere Container-Systeme konfiguriert werden.

Unabhängig von der verwendeten Lösung, müssen die Systeme in einen definierten Zustand geführt werden. Dieser Vorgang kann einen größeren Zeitraum in Anspruch nehmen und benötigt entsprechende manuelle Resourcen. Um diesen Zeitraum zu verringern, sollten anhand des Konfigurationsmanagements exemplarische Systeme vorbereitet und in gepackter Form abgelegt werden. Bei den meisten Lösungen wird diese Form ``Image'' genannt. Wie bereits bei ``Artefakt-Repositories'' angesprochen, sollten diese Images nachvollziehbar benannt und abgelegt werden. Es sollte möglich sein eine Verbindung zur jeweiligen System-Konfiguration herzustellen. Bestenfalls ist die System-Konfiguration in einer Versionsverwaltung abgelegt und die entsprechende Version kann ebenfalls zur Referenzierung des System-Images verwendet werden. Im Rahmen des automatisieren Bereitstellungsprozesses, wäre es auch sinnvoll die verwendet Systemkonfiguration in der Entsprechenden System-Übersicht aus Kapitel~\ref{subsubsec:configuration-system-overview} zu aktualisieren.

\section{Best Practices in der Softwareentwicklung}

Feature-Branches verhindern keine Hindernisse, die beim Zusammenführen von Änderungen auftreten. Sie helfen lediglich, das Auftreten der Probleme, durch die Hindernisse, zu einem gewählten Zeitpunkt zu verschieben. Daher sind Entwickler, auch mit Features-Branches, darauf angewiesen Entwicklungsmuster anzuwenden und sich mit der Softwarearchitektur der Anwendung auseinanderzusetzen.

Viele dieser Entwicklungsmuster und -verfahren werden unter dem Begriff ``Best Practices'' geführt. Sie unterstützen Entwickler in Entwurfsentscheidungen und geben Rahmen für Standards in der Softwareentwicklung. Viele der Best-Practices zielen zudem auf Verbesserungen für Wartbarkeit, Robustheit und allgemeine geringere Umsetzungsaufwände.

\subsection{Modularisierung von Software}

Viele Probleme bei Continuous-Integration und Feature-Branches entstehen bei komplizierten Merge-Verfahren. Viele komplizierte Merge-Schritte begründen sich häufig durch einen zu hohen Kopplungsgrad der Software. Wenn Komponenten stark gekoppelt sind, ist es oft notwendig mit mehreren Entwicklern in gleichen Code-Abschnitten zu interagieren. Wird eine Software von Beginn an lose gekoppelt entwickelt, ergeben sich oft deutlich weniger Abhängigkeiten und komplizierte Merge-Schritte werden vermieden.

Die lose Kopplung einer Software kann, durch das Einhalten der Prinzipien zur Modularisierung\footcite{2012-barth-modularisation}, erreicht werden. 

\paragraph{Information Hiding} ist ein von Parnas\footcite{1972-parnas} geprägter Begriff. Als Basis für die Modularisierung und Dekomposition von Software wird drei Schritten gefolgt:
\begin{itemize}
\item Ermittle alle Entwurfsentscheidungen, welche sich potentiell ändern werden.
\item Erstelle pro Entwurfsentscheidung ein Modul, die Entwurfsentscheidung wird ``Geheimnis des Moduls'' genannt.
\item Die Schnittstelle zum Modul sollte robust genug sein, um bei einer Änderung des Geheimnisses nicht verändert zu werden.
\end{itemize}
Durch die Einhaltung der Prinzipien, werden mögliche Änderungen auf ein Modul beschränkt und damit die Auswirkungen begrenzt.
\paragraph{Separation of Concerns} ist ein Basisprinzip moderner Softwareentwicklung. Während Information-Hiding auf einer niedrigen Modulebene ansetzt, versucht die ``Aufteilung nach Anliegen'' höher anzusetzen. Die Teile eines Moduls sollen nach möglich Anliegen  mit möglich wenig Überlappungen eingeteilt werden. 
\paragraph{Low Coupling Cohesion} beschreibt das Verbindungs- und Kommunikationsverhalten der Module. Es wird eine hohe Kohäsion innerhalb eines Moduls angestrebt und eine geringe zu anderen Modulen.

Werden die Prinzipien befolgt, ergeben sich Vorteile für die Wartbarkeit, Wiederverwendbarkeit und Robustheit der Anwendung. Die Konzentrierten Verbindungen sorgen zudem für eine geringere Schnittmenge von Änderungen durch Entwickler.

Eine modernere Form der Modularisierung sind die ``serviceorientierten Architekturen''. Diese beschreiben Anwendungsszenarien in verschiedenen Granularität. Die Kapselung in Services ermöglichen die Komposition und Orchestrierung von komplexen Vorgängen. Der serviceorientierte Ansatz nutzt die Prinzipien der Modularisierung und bietet die Vorteile unter neuem Namen an.

\subsection{Fortgeschrittene Nutzung von Versionsverwaltung}

Wie auch mit jeder anderen Versionsverwaltung, so ist es auch beim Arbeiten mit Git essentiell, seine Arbeit zu strukturieren. Wird Git lediglich als bequeme Variante für eine regelmäßige Sicherung des Arbeitsstandes genutzt, dann entsteht sehr schnell eine schwer zu lesende, an Bedeutung mangelnde Versionshistorie. Wichtig ist es die getätigte Arbeit in semantisch zusammenhängenden, möglichst kleine und prägnanten Commits zu gliedern. Ein Commit sollte immer nur eine Änderung zusammenfassen. Dadurch ist es möglich feingranulare Commit-Nachrichten zu verfassen.
Zusammen mit nachvollziehbaren und klaren Commit-Nachrichten, entsteht so eine gut leserliche und die Dokumentation unterstützende Versionshistorie.\footcite[vgl.][Kap. Making only one change per commit]{git-essentials-2017}

\footcite[Writing commit messages before starting to code][]{git-essentials-2017}

Including the whole change in one commit

Describing the change, not what have you done

\subsection{Testgetriebene Entwicklung}
\label{test-driven-development}

Testgetriebene Entwicklung, oder auch Test-Driven-Development(TDD) wurde bereits von Kent Beck 1999 als ``test-first''-Ansatz propagiert. Seitdem hat dieses Vorgehen viele Anhänger gewonnen. Es fordert ein Umdenken beim Entwickler. Zuerst muss das Ergebnis einer Änderung oder einer Neuerung bekannt sein und erst danach kann der umsetzende Code entwickelt werden\footcite[vgl.][Kap. Understanding TDD]{tdd-java}. Die Umkehrung des Zeitpunktes, wann die Tests verfasst werden, fördert die Qualität der Entwicklung. Es werden die Anzahl der auftretenden Fehler reduziert, entkoppelte Strukturen gefördert und die Anzahl der nachträglich auftretenden Fehler deutlich gemindert\footcite[vgl.][]{tdd-ci-effectivness}.
Insbesondere im Continuous-Integration-Bereich ist TDD als Continuous-Testing sinnvoll, da nur kontinuierlich getesteter Code auch kontinuierlich zuverlässig integriert werden kann.

Die Art und Weise der Anwendung von TDD kann stark variieren. Daher wird eine stark iterative Variante des Schreibens von Tests angestrebt. Das ``Red Green Refactoring''\footcite[vgl.][Kap. 
Red-Green-Refactor
]{tdd-java} fordert immer nur minimale Anpassungen vorzunehmen, bis der Test vollständig ist. Nach jeder Anpassung, die den Test fehlschlagen lässt, muss die getestete Implementierung so angepasst werden, dass der Test erfolgreich verläuft. Ist der Test vollständig muss abschließend die Implementierung einem Refactoring unterzogen werden. Basierend auf der begrenzten gedanklichen Kapazität eines Entwicklers, soll so immer nur ein Gesichtspunkt der Entwicklung betrachtet werden. Zuerst soll das korrekte Verhalten der Software sichergestellt werden. Danach ist die korrekte Struktur der Software herzustellen. Die Dualität der Betrachtung und der minimal inkrementelle Ansatz sollen ein hoch qualitatives Resultat ergeben.

Über die Lehrmethoden von TDD sind bekannte Verbindungen von Anforderungsmanagement und Testfallerstellung, wieder in den Fokus gerückt. Unter der Bezeichnung ``Behaviour-Driven-Development''\footcite{bdd-north} entstand ein Verfahren zur Verbindung beider Bereiche. Mittels einer der Umgangssprache nahen DSL wird versucht eine leserliche Dokumentation zu erstellen. Nutzerszenarien werden in einer Gegeben-Wenn-Dann-Notation\footcite{fowler-gwt} verfasst und können durch die strukturierte Notation direkt mit Test-Code verknüpft werden. Damit wird angestrebt die Barrieren zwischen Projektteilnehmern ohne Programmierkenntnissen, Testern und Entwicklern zu verringern.

\subsection{Verwendung von Monorepo-Repositories}

Im Abschnitt~\ref{subsubsec:illustrate-dependencies}~``\nameref{subsubsec:illustrate-dependencies}'', konnten gut Abhängigkeitsgruppierungen erkannt werden. Gerade bei Abhängigkeitskonstrukten innerhalb einer Organisation, werden häufig Änderungen parallel in mehreren Abhängigkeiten vorgenommen. Gerade wenn sich diese Abhängigkeiten gegenseitig bedingen, kann es zu einem erhöhten Aufwand kommen. Damit ein gemeinsamer Stand erreicht wird, müssen häufig mehrere Teile des Projektes aktualisiert werden. Gerade wenn ein experimentelles Feature auf mehreren zusammenhängenden Feature-Branches getestet werden muss, entsteht ein deutlich erhöhter Aufwand.

Eine Variante diese Aufwände zu reduzieren und Tests, sowie Auslieferung von Software für ein Paket von Abhängigkeiten zu optimieren, sind Monorepos. Monorepos verwenden, im Kontrast zu regulären Praktiken, ein Repository für mehrere Abhängigkeiten\footcite{trunkbaseddevelopment-monorepo}. Dieses Vorgehen hat den direkten Vorteil, dass Abhängigkeiten nicht miteinander verlinkt werden müssen. Abhängigkeiten sind durch das gemeinsam geteilte Repository automatisch verbunden. Zudem können gemeinsam verwendete Werkzeug einfach gleichgeschaltet und die gemeinsame Verwendung begünstigt werden.

Die Verwendung eines Monorepos vereinfacht zwar die Abhängigkeitsverwaltung, birgt allerdings Schwierigkeiten für größere Repositories. Während in Repositories getrennte Abhängigkeiten, auch die Commits logisch und physisch getrennt sind, fällt diese Barriere in Monorepos. Es müssen daher zusätzliche Mechanismen für die Übersicht geschaffen werden.

Ein weiterer Punkt ist die Performance. Abhängig vom gewählten Versionsverwaltungssystem, können gerade mit Git hier Probleme auftreten. Da Git immer die vollständige Historie bereit hält, sind Performance-Probleme spürbar\footcite{atlassian-monorepo-git}. In zentralen Systemen wie SVN können für Monorepos gezielte Teilebereiche des Repos verwendet werden. 
In jedem Versionsverwaltungssystem ist hingegen die erhöhte Commit-Frequenz spürbar. Merges treten deutlich häufiger auf, zusätzliche manuelle Eingriffe sind teilweise notwendig.

Trotz der Schwierigkeiten nutzen große Unternehmen wie Google, Facebook und Twitter sehr große Monorepos. Für alle drei Unternehmen ist die Verwendung von Monorepos allerdings mit großem Aufwand verbunden. Google entwickelte eine eigene Versionsverwaltung, Facebook investiert in Mercurial und Twitter verwendet eine speziell angepasste Git-Variante\footcite{monorepos-wild}.
Bei entsprechender Größe des Projektes, ist allerdings auch für kleinere Unternehmen die Verwendung von Monorepos nützlich\footcite{hackernoon-positive-monorepo}.

\section{Prototyp zur Feature-Branch-Visualisierung}

Mit wachsender Beliebtheit von Feature-Branches, erweiterten auch die Anbieter für Continuous-Integration-Lösungen ihr Angebot. Viele Anbieter stellen umfangreiche Angebote für Continuous-Deployment bereit. Oftmals sind auch zusätzliche Optionen für Feature-Branches enthalten. Wie im Git-Workflow vorgestellt, werden diese Feature-Branches durch einen manuellen Merge-Befehl auf einem Release-Branch akkumuliert. Auf diese Weise werden kontinuierlich, wenn auch verzögert, die einzelnen Feature-Branches mit einander zusammengeführt. Das späte Feedback zum Zeitpunkt der Zusammenführung, kann zu Problemen und zur Verzögerungen beim Release führen. Eine direkte Alternative ist es, die jeweiligen Feature-Branches direkt zum Zeitpunkt ihrer Fertigstellung zusammenzuführen. Für jeden weiteren Feature-Branch, der zusammengeführt werden muss, ergeben sich allerdings die gleichen Problem, wie bereits zuvor.
Eine mögliche Lösung wäre es Release bereits im Vorfeld zu definieren und die dazugehörigen Branches zu verfolgen. Somit können Konflikten in Codeständen und potentielle Fehlerquellen eher erkennen. Sind alle Feature-Branches konfliktfrei, können diese automatisch zu einem Release gebündelt werden. Jeder einzelne Branch kann durch Tests und Metriken unterstützt werden. Zudem können auf diese Weise Features zurückgehalten werden, die fertig gestellt wurden, aber aus politischen Gründen noch nicht Teil des Releases sein dürfen. 
Die Behebung von Merge-Konflikten bedeutet, dass einer der beiden vom Konflikt betroffenen Branches, Teile des Codes des anderen Branches, mit aufnehmen muss. Daher ist es möglich, dass auch mit der Verwendung von Feature-Branches, das gezielte zurückhalten von Features, schwierig bleibt. Daher können dieses beiden Branches nicht ohne ein Feature-Toggle unabhängig von einander veröffentlicht werden.

Der Prototyp soll somit die folgenden Punkte unterstützen:
\begin{itemize}
\item Gruppierung von Feature-Branches zu Releases
\item Darstellung der Untermenge an Branches, welche bereits zu einem Release kombiniert werden können
\item Darstellung der Testergebnisse, Testabdeckung und Code-Qualitätsmetriken
\item Bereitstellung einer API um Testergebnisse und Metriken mit einem Continuous-Integration-System zu synchronisieren
\end{itemize}

\subsection{Anforderungen}

Ziel des Prototyps ist es Release-Informationen zu einem Projekt anzuzeigen. Daher müssen Projekte angelegt und bearbeitet werden. Zudem müssen die zugehörigen Repository-Informationen ausgelesen werden. Weiter sollten Abhängigkeiten des Projektes ausgelesen und ausgewertet werden. 

Um einzuordnen, welche Änderungen zu einem Release gehören, müssen diese Änderungen definiert werden. Im Fall von Feature-Branches müssen die Feature-Branches deklariert werden, welche Teil des Releases werden. Damit ein Release aussagekräftig deklariert wird, sollten zudem Feature-Branches innerhalb der Abhängigkeiten deklariert werden.

Ist das Release definiert, sollen eine Reihe an Fragen einfach zu beantworten sein. 
\begin{itemize}
\item Können alle Feature-Branches zusammengeführt werden?
\item Welche Branches würde einen Konflikt mit welchem anderen Branch auslösen?
\item Wie sieht die derzeit minimal release-fähige Untermenge an Feature-Branches aus?
\item Welche Branches wurden erfolgreich getestet?
\item Wie verhalten sich die Metriken der Feature-Branches untereinander und zum Haupt-Branch?
\end{itemize}

Des Weiteren sollte die Anwendung an einen bestehenden Continuous-Prozess möglich sein. Es sollte daher eine REST-API bereit gestellt werden. Die API soll primär die Daten für Metriken und Testergebnisse entgegennehmen.

\subsection{Nutzungsszenarien (Use-Cases)}

Aus den Anforderungen ergeben sich einige Nutzungsszenarien. Es soll keine vollständige Projektspezifikation für den Prototypen erstellt werden, daher werden die Nutzungsszenarien nur angerissen. 

\paragraph{Projekt registrieren}
Um die Projekte zu analysieren, müssen sie angelegt werden. Im optimal Fall geschieht dies durch die Angabe eines Repositories. Aus diesem Repository können, anhand der Beschreibungsdatei der verwendeten Packetverwaltung, die weiteren Informationen gewonnen werden.

\paragraph{Branches auflisten}
Um die Feature-Branches für ein Release zu selektieren, müssen alle verfügbaren Branches des Projektes dargestellt werden. 

\paragraph{Release erstellen}
Die Release-Erstellung erfolgt durch die Wahl eines Namens und der Selektion der gewünschten Branches. Der Release wird dem Projekt zugeordnet und kann über das Projekt angezeigt werden.

\paragraph{Branch-Details darstellen}
Um einen Branch zu bewerten, müssen Tests und Metriken für den Branch ausgeführt werden. Die Ausführung und die Sammlung der Daten werden außerhalb des Tools durchgeführt, daher werden diese Daten über eine API zugeführt.

\paragraph{Branch-Konflikte anzeigen}
Zur weiteren Bewertung der Branches müssen Merge-Konflikte zwischen den Branches ermittelt werden. Branche die einen Konflikt aufweisen, sollten in der Release-Übersicht markiert und gruppiert werden.

\paragraph{Release erstellen}
Um Wunsch wird ein Release-Branch erstellt und alle Branches, die keinen Konflikt aufweisen, werden zusammengeführt.

\subsection{Grundlagen der Umsetzung}

Da der Prototyp als Unterstützung für bestehende Werkzeuge agieren soll, bietet sich ein modernes Web-Framework an. Durch die berufliche Prägung des Autors der Masterarbeit, liegt der Fokus zudem auf PHP. Die Wahl für ein modernes und flexibles Framework fällt daher auf Symfony, welches sich durch Flexibilität und Modularität auszeichnet. Zudem existiert für Symfony eine sehr aktive Community, welche Zahlreiche Werkzeug und Hilfsbibliotheken bereit stellt. Durch Symfony ergibt sich als bevorzugte Abhängigkeitsverwaltung Composer.  

\subsection{Domainmodell}

Das betrachtet Problem betrifft sowohl Repository-Artefakte, als auch Projekt- und Release-Details. Weiter müssen Metriken und Testergebnisse protokolliert werden. Da die Erstellung von Metriken und Tests eine größere Zeitspanne benötigen können, müssen die Ergebnisse in jedem Fall persistiert werden. Ist zudem gefordert, dass der Zugriff auf das Versionsverwaltungssystem nur im Command-Line-Level erfolgen darf und nicht über die Webschnittstelle, ist auch hier die Notwendigkeit der Persistierung gegeben.

\begin{figure}[htbp]
  \includegraphics[
    width=\textwidth,
    height=\textheight,
    keepaspectratio
  ]{resources/ReleaseWardenClassChart.pdf}
  \caption{Klassendiagramm für Domainmodell}
  \label{class-chart-release-warden}
\end{figure}

In Abbildung~\ref{class-chart-release-warden} wird das Domainmodell in einem UML-Klassendiagramm dargestellt. Das Domainmodell beschreibt ein betrachtetes Projekt(Project) mit seinen Abhängigkeiten(Dependency) und den Releases für das Projekt. 
Um die Abhängigkeiten abzubilden und die verfügbaren Feature-Branches für ein Release zu selektieren, werden somit auch die Repositories und ihre Branches und Tags benötigt.

\subsection{Umsetzung der Nutzerszenarien}

\paragraph{Projekt registrieren}

\paragraph{Branches auflisten}

\paragraph{Release erstellen}

\paragraph{Branch-Details anzeigen}

\paragraph{Branch-Konflikte anzeigen}

\paragraph{Release erstellen}

Beschreibung von PHPMetrics


\section{Motivation, Disziplin und Verantwortung - Faktor Mensch}
\label{sec:human-fail}
Die vorangegangene Kapitel beschäftigen sich größtenteils mit Methodiken und Hilfsmitteln. Die Motivation dieser Methodiken und Hilfsmittel begrenzt sich unter anderem auf Wartbarkeit, Robustheit und Skalierbarkeit von Software. Dabei wird die Motivation für die Entwicklung, genauer für den Entwickler, weitestgehend ausgelassen.

Gerade in Anbetracht der Zeit, die viele der Methodiken bereits bekannt sind, ist es hilfreich einen weiteren Aspekt hinzuziehen. Dieser Aspekt soll den psychischen Teil der Einführung einer neuen Methodik beleuchten.

\subsection{Motivation}

Motivation kann durch drei Bereiche getragen werden\footcite[vgl.][]{codingame-drive}\footcite[vgl.][Kap. Autonomie ff.]{pink-drive}:
\begin{itemize}
\item Autonomie - die Möglichkeit sich selbst zu organisieren. Autonomie soll die eigenen Fähigkeiten möglichst voll zu nutzen.
\item Können - die Möglichkeit sich weiterzuentwickeln und Neues zu entdecken.
\item Bestimmung - die Möglichkeit an etwas mit Bedeutung mitzuwirken.
\end{itemize}

Die Einteilung ist eine Zusammenfassung mehrere einzelner Theorien und in manchen Teilen populärwissenschaftlich\footcite[vgl.][]{drive-scholarly-review}. Basierend auf den drei Bereichen, können die Methodiken besser argumentiert und die generelle Bereitschaft zur Einführung gestärkt werden. Generell sollte jeder Teilnehmer einer Methodik sich darin wiederfinden. Methodiken die sich nicht im Alltag des Entwicklungsteams wiederfinden, werden auf lange Sicht verschwinden oder zur Belastung.

\subsection{Disziplin}

Viele eingeführte Hilfsmittel, Methodiken oder Ideen verschwinden wieder. Oftmals fehlen Träger und Fürsprecher. Häufig fehlt es aber auch an Disziplin. Entscheidend ist die Einsicht zur Selbstdisziplin. Viele agile Methodiken basieren auf Selbstorganisation und Eigenverantwortung\footcite[vgl.][]{codingame-agile-failed}. Viele der Methodiken basieren auf einem Entwickler, der bereit ist stetig zu wachsen und an sich zu arbeiten.
Disziplin greift nach der Motivation. Nach der Einführung einer neuen Methodik, benötigt es oft Disziplin diese aktiv zu nutzen\footcite[vgl.][]{screw-motivation}. Es benötigt konstante Arbeit und Reflexion zur Nutzung und Erhaltung einer neuen Methodik.

Oftmals ist eine neue Methodik damit verbunden, alte Verhaltensweisen abzulegen.
Gelernte Verhaltensweise lassen sich oft eine Folge von drei Punkten gliedern.
\begin{itemize}
\item Auslöser - die Situation, welche eine Gewohnheit auslöst oder diese einleitet.
\item Verhalten - der Ablauf oder das Verhalten, welches die Gewohnheit darstellt.
\item Nutzen - der Nutzen, welchen das Verhalten erzeugt.
\end{itemize}
Die Hemmschwelle zur Einführung einer neuen Methodik sollte möglichst gering gehalten werden. Dazu bietet es sich an die Methodik an bereits existierende Mechanismen zu knüpfen. Zudem sollte der Aufwand zur Nutzung sehr gering sein und der Nutzen durch eine Rückkopplung spürbar\footcite[vgl.][]{steps-of-habit}.

\subsection{Verantwortung}

Auch eine Methodik die durch Träger und Fürsprecher eingeführt wird, sollte in der Verantwortung des ganzen Entwicklungsteam liegen. Die Einhaltung der Methodik sollte jeden, der sie missachtet, in die Verantwortung ziehen.
Wie auch in vielen agilen Methodiken, ist eine gemeinsame Fürsprache, ein gemeinsames ``Commitment'' notwendig. Ein gemeinsames Commitment sollte, wenn möglich, durch technische Hilfsmittel unterstütze werden. Für viele gemeinsame Regeln existieren automatisierte Prüfungen oder Integrationen für die Entwicklungsumgebung und den automatisierten Software-Erstellungsprozess.
Auch der Review-Prozess für Softwareänderungen kann hierbei unterstützen. Entwickler sollten sich stets gegenseitig auf die Missachtung von Coding-Guidelines und Entwicklungsmustern hinweisen.

\subsection{Faktor Mensch}

Die Erstellung von Software verlangt eine breite Palette an Fähigkeiten. Zudem fehlen in der Softwareerstellung viele der standardisierten Vorgehensweisen der Ingenieursdisziplinen. Häufig werden kreative und pragmatische Lösungen benötigt.

\blockquote {discipline, the most lacking virtue in creative people (like programmers)}\footcite[][S.167]{git-essentials-2017}
\vspace{1em}\\
Die fehlenden Standards und Notwendigkeit für kreativen Lösungen von Entwicklern, sind ein zu respektierendes Risiko in der Softwareentwicklung. Fordernde und anspruchsvolle Methodiken sind nicht für alle Softwareentwickler geeignet. Laufende Projekte und bestehende Belastungen sind bei der Einführung neuer Methodiken stets zu beachten. Die Einführung neuer Methodiken in bereits belastete oder scheiternde Projekte führen oft zu schlimmeren Ergebnissen.

Neue Methodiken sollten stets mit dem nötigen Raum eingeführt werden. Zudem sollte eine regelmäßige Betrachtung des Verhältnisses von Aufwand und Nutzen erfolgen.
